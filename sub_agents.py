from datetime import datetime

from IPython.display import Image, display
from langchain.chat_models import init_chat_model
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

from prompts import SUBAGENT_USAGE_INSTRUCTIONS
from state import DeepAgentState
from task_tool import _create_task_tool
from utils import format_messages

# Limits
max_concurrent_research_units = 3
max_researcher_iterations = 3

# Mock search result
search_result = """The Model Context Protocol (MCP) is an open standard protocol developed 
by Anthropic to enable seamless integration between AI models and external systems like 
tools, databases, and other services. It acts as a standardized communication layer, 
allowing AI models to access and utilize data from various sources in a consistent and 
efficient manner. Essentially, MCP simplifies the process of connecting AI assistants 
to external services by providing a unified language for data exchange. """


# Mock search tool
@tool(parse_docstring=True)
def web_search(
    query: str,
):
    """Search the web for information on a specific topic.

    This tool performs web searches and returns relevant results
    for the given query. Use this when you need to gather information from
    the internet about any topic.

    Args:
        query: The search query string. Be specific and clear about what
               information you're looking for.

    Returns:
        Search results from the search engine.

    Example:
        web_search("machine learning applications in healthcare")
    """
    return search_result


def call_sub_agents():
    # Add mock research instructions
    SIMPLE_RESEARCH_INSTRUCTIONS = """You are a researcher. Research the topic provided to you. IMPORTANT: call to the web_search tool and use the result provided by the tool to answer the provided topic."""

    # Create research sub-agent
    research_sub_agent = {
        "name": "research-agent",
        "description": "Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.",
        "prompt": SIMPLE_RESEARCH_INSTRUCTIONS,
        "tools": ["web_search"],
    }

    # Create agent using create_react_agent directly
    model = init_chat_model(model="google_genai:gemini-2.5-flash", temperature=0.0)

    # Tools for sub-agent
    sub_agent_tools = [web_search]

    # Create task tool to delegate tasks to sub-agents
    task_tool = _create_task_tool(
        sub_agent_tools, [research_sub_agent], model, DeepAgentState
    )

    # Tools
    delegation_tools = [task_tool]

    # Create agent with system prompt
    agent = create_react_agent(
        model,
        delegation_tools,
        prompt=SUBAGENT_USAGE_INSTRUCTIONS.format(
            max_concurrent_research_units=max_concurrent_research_units,
            max_researcher_iterations=max_researcher_iterations,
            date=datetime.now().strftime("%m %d %Y"),
        ),
        state_schema=DeepAgentState,
    )

    result = agent.invoke(
        {
            "messages": [
                {
                    "role": "user",
                    "content": "Give me an overview of the Model Context Protocol.",
                }
            ],
        }
    )

    format_messages(result["messages"])